# Voice Emotion Detector

Real-time speech emotion recognition from your microphone using AI. Detects **7 emotions** with **92% accuracy** and transcribes what you said.

## Features

- **7 Emotion Detection**: Angry, Disgust, Fearful, Happy, Neutral, Sad, Surprised
- **Speech-to-Text**: Transcribes your speech using OpenAI Whisper
- **Real-time Analysis**: Record from your microphone with start/stop control
- **Modern Web UI**: React frontend with FastAPI backend
- **High Accuracy**: 92% accuracy using Whisper-based emotion model

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  React + FastAPI Architecture                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚   React Frontend     â”‚  HTTP   â”‚   FastAPI Backend       â”‚  â”‚
â”‚   â”‚   (Vite + TypeScript)â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   (Python + uvicorn)    â”‚  â”‚
â”‚   â”‚                      â”‚         â”‚                         â”‚  â”‚
â”‚   â”‚   - MediaRecorder    â”‚  POST   â”‚   - POST /api/analyze   â”‚  â”‚
â”‚   â”‚   - WAV conversion   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   - Emotion classifier  â”‚  â”‚
â”‚   â”‚   - Results display  â”‚         â”‚   - Speech transcriber  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   Frontend: http://localhost:3000                                â”‚
â”‚   Backend:  http://localhost:8000                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Models Used

| Model | Purpose | Size |
|-------|---------|------|
| `openai/whisper-base` | Speech-to-Text | ~140MB |
| `firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3` | Emotion Detection | ~600MB |

## Detected Emotions

| Emotion | Emoji |
|---------|-------|
| Angry | ğŸ˜  |
| Disgust | ğŸ¤¢ |
| Fearful | ğŸ˜¨ |
| Happy | ğŸ˜Š |
| Neutral | ğŸ˜ |
| Sad | ğŸ˜¢ |
| Surprised | ğŸ˜² |

## Requirements

- **Python**: 3.10 or higher
- **Node.js**: 18 or higher
- **ffmpeg**: Required for audio processing
- **RAM**: 4GB minimum (8GB recommended)
- **Disk**: ~2GB for model downloads

### Installing ffmpeg

**macOS**:
```bash
brew install ffmpeg
```

**Ubuntu/Debian**:
```bash
sudo apt install ffmpeg
```

**Windows**:
```bash
# Using Chocolatey
choco install ffmpeg

# Or using Scoop
scoop install ffmpeg
```

## Quick Start

```bash
# Clone the repository
git clone https://github.com/manishmitra017/voice_guard_rail.git
cd voice_guard_rail

# Install uv (Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install Python dependencies
uv sync

# Install frontend dependencies
cd frontend && npm install && cd ..

# Start both servers
./start-local.sh
```

Open **http://localhost:3000** in your browser.

### Manual Start

```bash
# Terminal 1: Start FastAPI backend
uv run uvicorn api.main:app --host 127.0.0.1 --port 8000

# Terminal 2: Start React frontend
cd frontend && npm run dev
```

## Project Structure

```
voice_guard_rail/
â”œâ”€â”€ api/                        # FastAPI backend
â”‚   â””â”€â”€ main.py                 # API endpoints
â”œâ”€â”€ frontend/                   # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx             # Main React component
â”‚   â”‚   â””â”€â”€ App.css             # Styles
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ src/                        # Core ML modules
â”‚   â”œâ”€â”€ emotion_classifier.py   # 7-emotion Whisper model
â”‚   â””â”€â”€ speech_transcriber.py   # Whisper speech-to-text
â”œâ”€â”€ start-local.sh              # Local dev script
â””â”€â”€ pyproject.toml              # Python dependencies
```

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check + model status |
| `/analyze` | POST | Analyze audio file (multipart form) |
| `/emotions` | GET | List all detectable emotions |

### Example API Usage

```bash
# Health check
curl http://localhost:8000/health

# Analyze audio file
curl -X POST http://localhost:8000/analyze \
  -F "audio=@recording.wav"
```

## Troubleshooting

### Microphone Access

**macOS**: System Preferences â†’ Security & Privacy â†’ Privacy â†’ Microphone â†’ Enable for browser

**Linux**:
```bash
# Add user to audio group
sudo usermod -a -G audio $USER
```

### Model Download Issues

```bash
# Clear HuggingFace cache
rm -rf ~/.cache/huggingface
```

## License

MIT License
