# Voice Emotion Detector

Real-time speech emotion recognition from your microphone using AI. Detects **7 emotions** with **92% accuracy** and transcribes what you said.

## Features

- **7 Emotion Detection**: Angry, Disgust, Fearful, Happy, Neutral, Sad, Surprised
- **Speech-to-Text**: Transcribes your speech using OpenAI Whisper
- **Real-time Analysis**: Record from your microphone with start/stop control
- **Web Interface**: Clean Streamlit UI with visual emotion display
- **High Accuracy**: 92% accuracy using Whisper-based emotion model

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           VOICE EMOTION DETECTOR                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚   â”‚  ğŸ¤ Record   â”‚  Click "Start Recording" â†’ Speak â†’ Click "Stop"      â”‚
â”‚   â”‚  (Mic Input) â”‚                                                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚          â”‚                                                               â”‚
â”‚          â”‚  16kHz WAV audio                                              â”‚
â”‚          â–¼                                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚                    AUDIO PROCESSING                           â”‚      â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚   â”‚                      â”‚                                        â”‚      â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚
â”‚   â”‚   â”‚   Whisper    â”‚   â”‚   â”‚  Whisper Emotion Classifier    â”‚  â”‚      â”‚
â”‚   â”‚   â”‚   (base)     â”‚   â”‚   â”‚  (large-v3 fine-tuned)         â”‚  â”‚      â”‚
â”‚   â”‚   â”‚              â”‚   â”‚   â”‚                                 â”‚  â”‚      â”‚
â”‚   â”‚   â”‚  Speech to   â”‚   â”‚   â”‚  Audio â†’ Mel Spectrogram â†’     â”‚  â”‚      â”‚
â”‚   â”‚   â”‚  Text        â”‚   â”‚   â”‚  Transformer â†’ 7 Emotions      â”‚  â”‚      â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚
â”‚   â”‚          â”‚           â”‚                  â”‚                     â”‚      â”‚
â”‚   â”‚          â–¼           â”‚                  â–¼                     â”‚      â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚
â”‚   â”‚   â”‚ "Hello, how  â”‚   â”‚   â”‚  ğŸ˜Š Happy (85.2%)              â”‚  â”‚      â”‚
â”‚   â”‚   â”‚  are you?"   â”‚   â”‚   â”‚  ğŸ˜ Neutral (10.1%)            â”‚  â”‚      â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚  ğŸ˜¢ Sad (2.3%)                 â”‚  â”‚      â”‚
â”‚   â”‚                      â”‚   â”‚  ...                            â”‚  â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚                      STREAMLIT UI                             â”‚      â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚
â”‚   â”‚  â”‚  ğŸ“ What You Said: "Hello, how are you?"                â”‚ â”‚      â”‚
â”‚   â”‚  â”‚  ğŸ­ Detected Emotion: ğŸ˜Š Happy (85.2% confidence)       â”‚ â”‚      â”‚
â”‚   â”‚  â”‚  ğŸ“Š All Scores: [bar chart of 7 emotions]               â”‚ â”‚      â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Models Used

| Model | Purpose | Size | Source |
|-------|---------|------|--------|
| `openai/whisper-base` | Speech-to-Text | ~140MB | [OpenAI Whisper](https://github.com/openai/whisper) |
| `firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3` | Emotion Detection | ~600MB | [HuggingFace](https://huggingface.co/firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3) |

## Detected Emotions

| Emotion | Emoji | Color |
|---------|-------|-------|
| Angry | ğŸ˜  | Red |
| Disgust | ğŸ¤¢ | Green |
| Fearful | ğŸ˜¨ | Purple |
| Happy | ğŸ˜Š | Green |
| Neutral | ğŸ˜ | Gray |
| Sad | ğŸ˜¢ | Blue |
| Surprised | ğŸ˜² | Yellow |

## Requirements

- **Python**: 3.10 or higher
- **OS**: macOS (tested), Linux, Windows
- **RAM**: 4GB minimum (8GB recommended)
- **Disk**: ~2GB for model downloads
- **Microphone**: Built-in or external

## Installation

### 1. Clone the Repository

```bash
git clone https://github.com/manishmitra017/voice_guard_rail.git
cd voice_guard_rail
```

### 2. Install uv (Python Package Manager)

If you don't have `uv` installed:

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 3. Install Dependencies

```bash
uv sync
```

This will:
- Create a virtual environment automatically
- Install all Python dependencies
- Download required packages (~500MB)

### 4. Run the App

```bash
./start.sh
```

Or manually:

```bash
uv run streamlit run app.py
```

### 5. Open in Browser

Navigate to: **http://localhost:8501**

## First Run

On first run, the app will download AI models:

1. **Whisper base model** (~140MB) - for speech transcription
2. **Emotion classifier** (~600MB) - for emotion detection

This happens once and models are cached for future runs.

## Usage

1. **Click "Start Recording"** - begins capturing audio from your microphone
2. **Speak** - say something with emotion!
3. **Click "Stop Recording"** - stops recording and analyzes
4. **View Results**:
   - ğŸ“ **What You Said** - transcribed text
   - ğŸ­ **Detected Emotion** - primary emotion with confidence
   - ğŸ“Š **All Emotion Scores** - probability distribution

## Project Structure

```
voice_guard_rail/
â”œâ”€â”€ app.py                      # Streamlit web application
â”œâ”€â”€ start.sh                    # Quick start script
â”œâ”€â”€ pyproject.toml              # Python dependencies (uv)
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ audio_recorder.py       # Microphone recording (sounddevice)
    â”œâ”€â”€ emotion_classifier.py   # 7-emotion Whisper model
    â””â”€â”€ speech_transcriber.py   # Whisper speech-to-text
```

## Technical Details

### Audio Recording (`audio_recorder.py`)
- Uses `sounddevice` for cross-platform microphone access
- Records at 16kHz mono (required by models)
- Saves to temporary WAV file for processing

### Speech Transcription (`speech_transcriber.py`)
- Uses OpenAI Whisper (base model)
- Loads audio with `librosa` (no ffmpeg dependency)
- Returns transcribed text and detected language

### Emotion Classification (`emotion_classifier.py`)
- Uses Whisper-large-v3 fine-tuned on emotion datasets
- Trained on: RAVDESS, SAVEE, TESS, URDU datasets
- Returns 7 emotion probabilities with confidence scores

## Troubleshooting

### Microphone Access (macOS)

If the app can't access your microphone:

1. Go to **System Preferences** â†’ **Security & Privacy** â†’ **Privacy** â†’ **Microphone**
2. Enable access for **Terminal** or your IDE

### Microphone Access (Linux)

```bash
# Check if your user is in the audio group
groups $USER

# Add to audio group if needed
sudo usermod -a -G audio $USER
```

### Model Download Issues

If models fail to download:

```bash
# Clear HuggingFace cache and retry
rm -rf ~/.cache/huggingface
uv run streamlit run app.py
```

### Port Already in Use

```bash
# Use a different port
uv run streamlit run app.py --server.port 8502
```

## Development

### Install Dev Dependencies

```bash
uv sync --dev
```

### Run Tests

```bash
uv run pytest
```

### Lint Code

```bash
uv run ruff check .
```

## Future Improvements

- [ ] AWS deployment (EC2/ECS)
- [ ] Real-time streaming analysis
- [ ] Emotion history tracking
- [ ] Multiple language support
- [ ] Custom emotion model training

## License

MIT License

## Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition
- [HuggingFace](https://huggingface.co/firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3) - Emotion model
- [Streamlit](https://streamlit.io/) - Web interface
